[
  {
    "objectID": "newlab6.html",
    "href": "newlab6.html",
    "title": "Lab 6 - Machine Learning in Hydrology",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'dplyr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(tidymodels)\n\n\nWarning: package 'tidymodels' was built under R version 4.4.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.8     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.2.1     \n\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\nWarning: package 'dials' was built under R version 4.4.3\n\n\nWarning: package 'parsnip' was built under R version 4.4.3\n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\nWarning: package 'rsample' was built under R version 4.4.3\n\n\nWarning: package 'tune' was built under R version 4.4.3\n\n\nWarning: package 'workflows' was built under R version 4.4.3\n\n\nWarning: package 'yardstick' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\n\nCode\nlibrary(powerjoin)\n\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\n\nCode\nlibrary(glue)\nlibrary(vip)\n\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\n\nCode\nlibrary(baguette)\n\n\nWarning: package 'baguette' was built under R version 4.4.3\n\n\nCode\nlibrary(workflows)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(tune)\nlibrary(ranger)\n\n\nWarning: package 'ranger' was built under R version 4.4.3\n\n\nCode\nlibrary(xgboost)\n\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\n\n\nAttaching package: 'xgboost'\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\n\nCode\nlibrary(nnet)\n\n\nWarning: package 'nnet' was built under R version 4.4.3\n\n\n\n\nCode\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\n\nQuestion 1\nFrom the PDF, zero_q_freq represents the frequency of days where Q = 0 mm/day.\n\n\nCode\nlibrary(ggplot2)\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map()\n\n\n\n\n\n\n\n\n\nQuestion 2\n\n\nCode\ncamels %&gt;%\n  select(aridity, p_mean, q_mean) %&gt;% \n  drop_na() %&gt;%\n  cor()\n\n\n           aridity     p_mean     q_mean\naridity  1.0000000 -0.7550090 -0.5817771\np_mean  -0.7550090  1.0000000  0.8865757\nq_mean  -0.5817771  0.8865757  1.0000000\n\n\n\n\nCode\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  scale_color_viridis_c() +\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCode\nset.seed(123)\n\ncamels &lt;- camels %&gt;%\n  mutate(logQmean = log(q_mean))\n\n\n\n\nCode\ncamels_split &lt;- initial_split(camels, prop = 0.8)\n\ncamels_train &lt;- training(camels_split)\n\ncamels_test  &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\n\n\nCode\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_normalize(all_predictors()) %&gt;%\n  step_interact(terms = ~ aridity:p_mean) %&gt;% \n  step_naomit(all_predictors(), all_outcomes())\n\n\n\n\nCode\nbaked_data &lt;- prep(rec, camels_train) %&gt;% \n  bake(new_data = NULL)\n\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\n\nsummary(lm_base)\n\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -0.08342    0.02898  -2.879  0.00415 ** \naridity        -0.39770    0.06819  -5.832 9.51e-09 ***\np_mean          0.65025    0.06882   9.449  &lt; 2e-16 ***\naridity:p_mean  0.02389    0.01640   1.457  0.14583    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCode\nsummary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))\n\n\n\nCall:\nlm(formula = logQmean ~ aridity + p_mean + aridity_x_p_mean, \n    data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -0.08342    0.02898  -2.879  0.00415 ** \naridity          -0.39770    0.06819  -5.832 9.51e-09 ***\np_mean            0.65025    0.06882   9.449  &lt; 2e-16 ***\naridity_x_p_mean  0.02389    0.01640   1.457  0.14583    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCode\ntest_data &lt;-  bake(prep(rec), new_data = camels_test)\n\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\n\n\n\nCode\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\n\nCode\nggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +\n  # Apply a gradient color scale\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\n\n\n\nCode\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lm_model) %&gt;%\n  fit(data = camels_train) \n\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n\n                    Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept)      -0.08341681 0.02897625 -2.878799 4.152841e-03\naridity          -0.39769793 0.06818909 -5.832281 9.507063e-09\np_mean            0.65025318 0.06882050  9.448539 1.088651e-19\naridity_x_p_mean  0.02389458 0.01640487  1.456555 1.458304e-01\n\n\nCode\nsummary(lm_base)$coefficients\n\n\n                  Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept)    -0.08341681 0.02897625 -2.878799 4.152841e-03\naridity        -0.39769793 0.06818909 -5.832281 9.507063e-09\np_mean          0.65025318 0.06882050  9.448539 1.088651e-19\naridity:p_mean  0.02389458 0.01640487  1.456555 1.458304e-01\n\n\n\n\nCode\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\ndim(lm_data)\n\n\n[1] 135  61\n\n\n\n\nCode\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\n\nCode\nggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\n\nCode\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(rf_model) %&gt;%\n  fit(data = camels_train) \n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n\n[1] 135  60\n\n\n\n\nCode\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.596\n2 rsq     standard       0.736\n3 mae     standard       0.367\n\n\n\n\nCode\nggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\n\nCode\n#rec &lt;- recipe(logQmean ~ ., data = camels_train)\n\n\n\n\nCode\n#camels_train$outcome &lt;- factor(camels_train$outcome, levels = c(\"no\", \"yes\"))\n\n\n\n\nCode\nboost_mod &lt;- boost_tree() %&gt;%\n  set_engine('xgboost') %&gt;%\n  set_mode(\"regression\")\n\nnn_model &lt;- bag_mlp() %&gt;% \n  set_engine(\"nnet\") %&gt;% \n  set_mode(\"regression\")\n\n\n\n\nCode\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model, boost_mod, nn_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nCode\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_bag_mlp    Prepro… rmse    0.546  0.0254    10 recipe       bag_…     1\n2 recipe_bag_mlp    Prepro… rsq     0.788  0.0230    10 recipe       bag_…     1\n3 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     2\n5 recipe_rand_fore… Prepro… rmse    0.565  0.0270    10 recipe       rand…     3\n6 recipe_rand_fore… Prepro… rsq     0.769  0.0243    10 recipe       rand…     3\n7 recipe_boost_tree Prepro… rmse    0.607  0.0283    10 recipe       boos…     4\n8 recipe_boost_tree Prepro… rsq     0.740  0.0288    10 recipe       boos…     4\n\n\nIt seems as if the bagged MLP is the best bet for which model to use, as it has a lower rmse and higher rsq than the other models.\nBuild Your Own\nData Splitting\n\n\nCode\nset.seed(123)\n\nmy_camels_split &lt;- initial_split(camels, prop = 0.75)\n\nmy_camels_train &lt;- training(my_camels_split)\n\nmy_camels_test  &lt;- testing(my_camels_split)\n\nmy_camels_cv &lt;- vfold_cv(my_camels_train, v = 10)\n\n\nRecipe\n\n\nCode\nmy_rec &lt;-  recipe(logQmean ~ baseflow_index + soil_porosity, data = my_camels_train) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_normalize(all_predictors()) %&gt;%\n  step_interact(terms = ~ baseflow_index:soil_porosity) %&gt;% \n  step_naomit(all_predictors(), all_outcomes())\n\n\nI’m choosing these predictors because daily water discharge and the porosity of soil sound like they would have an impact on mean water discharge. Soils with greater porosity will likely have lower mean discharges, and areas with higher daily water discharges will likely have higher mean discharges.\nDefine 3 Models\n\n\nCode\nmy_rf &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nmy_lm &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nmy_boost &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\n\nWorkflow Set\n\n\nCode\nmy_wf &lt;- workflow_set(list(my_rec), list(my_lm, my_rf, my_boost)) %&gt;%\n  workflow_map('fit_resamples', resamples = my_camels_cv) \n\n\nEvaluation\n\n\nCode\nautoplot(my_wf)\n\n\n\n\n\n\n\n\n\n\n\nCode\nrank_results(my_wf, rank_metric = \"rsq\", select_best = TRUE)\n\n\n# A tibble: 6 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    1.04   0.0420    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.244  0.0357    10 recipe       rand…     1\n3 recipe_boost_tree Prepro… rmse    1.08   0.0465    10 recipe       boos…     2\n4 recipe_boost_tree Prepro… rsq     0.220  0.0396    10 recipe       boos…     2\n5 recipe_linear_reg Prepro… rmse    1.08   0.0411    10 recipe       line…     3\n6 recipe_linear_reg Prepro… rsq     0.179  0.0300    10 recipe       line…     3\n\n\nThe rand forest model fits this the best, as it has the lowest rmse and the highest rsq.\nExtract and Evaluate\n\n\nCode\nmy_lm_wf &lt;- workflow() %&gt;%\n  add_recipe(my_rec) %&gt;%\n  add_model(my_lm) %&gt;%\n  fit(data = my_camels_train) \n\nsummary(extract_fit_engine(my_lm_wf))$coefficients\n\n\n                                  Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept)                    -0.14577943 0.04968268 -2.934210 3.498276e-03\nbaseflow_index                  0.51722105 0.05090756 10.160006 3.642463e-22\nsoil_porosity                   0.07312772 0.04982638  1.467651 1.428304e-01\nbaseflow_index_x_soil_porosity -0.15324395 0.05951099 -2.575053 1.030998e-02\n\n\n\n\nCode\nmy_lm_data &lt;- augment(my_lm_wf, new_data = my_camels_test)\ndim(my_lm_data)\n\n\n[1] 168  61\n\n\n\n\nCode\nggplot(my_lm_data, aes(x = logQmean, y = .pred, colour = baseflow_index)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Baseflow Index\")\n\n\n\n\n\n\n\n\n\nNot gonna lie, these results are awful. There seems to be little correlation between any of the variables, and the LOBF doesn’t fit the scatterplot at all."
  },
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "lab6",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nWarning: package 'dplyr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.8     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.2.1     \n\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\nWarning: package 'dials' was built under R version 4.4.3\n\n\nWarning: package 'parsnip' was built under R version 4.4.3\n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\nWarning: package 'rsample' was built under R version 4.4.3\n\n\nWarning: package 'tune' was built under R version 4.4.3\n\n\nWarning: package 'workflows' was built under R version 4.4.3\n\n\nWarning: package 'yardstick' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(glue)\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.3\n\n\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\n\nif (file.exists(\"data/camels_vege.txt\")) {\n  print(\"File exists!\")\n} else {\n  print(\"File does not exist.\")\n}\n\n[1] \"File exists!\""
  }
]